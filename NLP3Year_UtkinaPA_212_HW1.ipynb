{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тональность отзывов на основе Firefox browser add-ons review - Reviews for YouTube High Definition, отзывы с рейтингами 1 и 5\n",
    "https://addons.mozilla.org/en-US/firefox/addon/youtube-high-definition/reviews/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для корректной работы мне пришлось установить через терминал следующие библиотеки и модели\n",
    "python3 -m spacy download en_core_web_sm\n",
    "pip install spaCy\n",
    "pip install langid\n",
    "pip install response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачиваем в список page с сайта url r страниц\n",
    "def upload(url, r):\n",
    "    session = requests.session()\n",
    "    page = []\n",
    "    for i in range(2, r):\n",
    "        link = url +str(i)\n",
    "        time.sleep(random.uniform(0.1, 0.2))\n",
    "        req = session.get(link)\n",
    "        page.append(req.text)\n",
    "    return(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating1_url = 'https://addons.mozilla.org/en-US/firefox/addon/youtube-high-definition/reviews/?score=1&utm_content=featured&utm_medium=referral&utm_source=addons.mozilla.org&page='\n",
    "rating5_url = 'https://addons.mozilla.org/en-US/firefox/addon/youtube-high-definition/reviews/?score=5&utm_content=featured&utm_medium=referral&utm_source=addons.mozilla.org&page='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачиваем отзывы с рейтингом 1 и 5, 6 и 26 страниц соответственно\n",
    "rating1 = upload(rating1_url, 8)\n",
    "rating5 = upload(rating5_url, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У отзывов с рейтингом 5 очень мало текстовых пояснений, кроме того, они написаны на разных языках, поэтому скачиваются все. Далее будет фильтрация отзывов на английском и выравнивание выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция, вынимающая текст отзыва\n",
    "def pars(ratings):\n",
    "    text = []\n",
    "    for item in ratings:\n",
    "        soup = BeautifulSoup(item, 'html.parser')\n",
    "        content = soup.find_all('div', {'class': 'ShowMoreCard-contents'})\n",
    "        l = len(content)\n",
    "        for i in range(l):\n",
    "            text.append(str(content[i])[40:-12]) #очищаем от тегов\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating5_text = pars(rating5)\n",
    "rating1_text = pars(rating1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть два списка отзывов, оба с большим количеством пустых элементов. Уберём их, они нам не нужны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "l = rating1_text.count('')\n",
    "for i in range(l):\n",
    "    rating1_text.remove('')\n",
    "l = rating5_text.count('')\n",
    "for i in range(l):\n",
    "    rating5_text.remove('')\n",
    "print(len(rating5_text))\n",
    "print(len(rating1_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just breaks youtube. no videos play, all videos just go to a profile post about covid.\n"
     ]
    }
   ],
   "source": [
    "# Образец отзыва\n",
    "print(rating1_text[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть два списка непустых отзывов, 173 положительных и 99 отрицательных, разница не слишком велика, поэтому для составления контрольных множеств используем оба списка полностью. Однако они на разных языках, поэтому нужно отобрать отзывы на английском как, во-первых, самые частотные, а во-вторых, пригодные для nltk и spaCy. Делать это будем с помощью библиотеки langid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langid\n",
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отбираем тексты на английском\n",
    "def eng(text):\n",
    "    text_eng = []\n",
    "    for a_text in text:\n",
    "        if langid.classify(a_text)[0] == 'en':\n",
    "            text_eng.append(a_text)\n",
    "    return(text_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 122\n"
     ]
    }
   ],
   "source": [
    "rating1_text = eng(rating1_text)\n",
    "rating5_text = eng(rating5_text)\n",
    "print(len(rating1_text), len(rating5_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# токенизируем тексты на английском: нижний регистр, без пунктуации, только слова\n",
    "def token(text):\n",
    "    text_preprocessed = []\n",
    "    for a_text in text:\n",
    "        a_tokens = [w.lower() for w in wordpunct_tokenize(a_text) if w.isalpha()]\n",
    "        text_preprocessed.extend(a_tokens)\n",
    "    return(text_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2853 1162\n"
     ]
    }
   ],
   "source": [
    "rating1_tokens=token(rating1_text)\n",
    "rating5_tokens=token(rating5_text)\n",
    "print(len(rating1_tokens), len(rating5_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем тестовую выборку, по 10 отзывов с рейтингами 1 и 5\n",
    "rating1_test = []\n",
    "rating5_test = []\n",
    "for i in range(10):\n",
    "    rating1_test.append(rating1_text[72+i])\n",
    "    rating5_test.append(rating5_text[112+i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убираем тестовые отзывы из основной выборки\n",
    "rating1_text = rating1_text[:72]\n",
    "rating5_text = rating5_text[:112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk лемматизирует довольно плохо, spacy справляется заметно лучше, будем использовать эту библиотеку\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Лемматизируем списки слов\n",
    "def lemma(tokens):\n",
    "    lemmas = []\n",
    "    for token in tokens:\n",
    "        lemmas.append(nlp(token)[0].lemma_)\n",
    "    return(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтрация по частотности, создание множества лемм\n",
    "def freq_filtre(lemmas, freq):\n",
    "    d = defaultdict(int)\n",
    "    res = set()\n",
    "    for lemma in lemmas:\n",
    "        d[lemma] += 1\n",
    "    for key in d.keys():\n",
    "        if d[key] > freq:\n",
    "            res.add(key)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "#формируем множества позитивных и негативных лемм, с фильтрацией по минимальной частотности от 1 до 3\n",
    "rating1_lemmas=lemma(rating1_tokens)\n",
    "rating5_lemmas=lemma(rating5_tokens)\n",
    "negat = []\n",
    "posit = []\n",
    "for freq in range(3):\n",
    "    r1 = freq_filtre(rating1_lemmas, freq)\n",
    "    r5 = freq_filtre(rating5_lemmas, freq)\n",
    "    negat.append(r1 - r5)\n",
    "    posit.append(r5 - r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338 158\n",
      "174 43\n",
      "133 23\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Проверим, действительно ли что-то отфильтровалось\n",
    "for i in range(3):\n",
    "    print(len(negat[i]), len(posit[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определяем тональность отзыва\n",
    "def tone(review, negat, posit):\n",
    "    res = ''\n",
    "    # лемматизируем отзыв\n",
    "    review_tokens = [w.lower() for w in wordpunct_tokenize(review) if w.isalpha()]\n",
    "    review_lemmas = set((nlp(token)[0].lemma_ for token in review_tokens))\n",
    "    if len(review_lemmas & negat) == 0 and len(review_lemmas & posit) == 0: # если в отзыве нет лемм из оценочных множеств, то и определить тональность нельзя\n",
    "        res = 'not stated'\n",
    "    elif len(review_lemmas & negat) == 0 or len(review_lemmas & posit)/len(review_lemmas & negat) > 1:\n",
    "        res = 'positive'\n",
    "    elif len(review_lemmas & posit) == 0 or len(review_lemmas & negat)/len(review_lemmas & posit) > 1:\n",
    "        res = 'negative'\n",
    "    else:\n",
    "        res = 'not stated' # сюда попадают отзывы с равным объёмом пересечений с каждым оценочным множеством\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверим, верно ли работает функция\n",
    "tone(rating1_text[69], negat[0], posit[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "#вычисляем переменные для расчёта accuracy. TP = pos(rating5_*), TN = neg(rating1_*), FP = pos(rating1_*), FN = neg(rating5_*)\n",
    "def accuracy_var(text, negat, posit):\n",
    "    neg = 0\n",
    "    pos = 0\n",
    "    ns = 0\n",
    "    for review in text:\n",
    "        res = tone(review, negat, posit)\n",
    "        if res == 'negative':\n",
    "            neg += 1\n",
    "        elif res == 'positive':\n",
    "            pos += 1\n",
    "        elif res == 'not stated':\n",
    "            ns += 1\n",
    "    return(neg, pos, ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtre at frequency  1\n",
      "True positive= 69 True negative= 68 False positive 0 False negative 0 Not stated 47\n",
      "Accuracy= 1.0\n",
      "Filtre at frequency  2\n",
      "True positive= 53 True negative= 70 False positive 1 False negative 12 Not stated 48\n",
      "Accuracy= 0.9044117647058824\n",
      "Filtre at frequency  3\n",
      "True positive= 49 True negative= 69 False positive 1 False negative 15 Not stated 50\n",
      "Accuracy= 0.8805970149253731\n"
     ]
    }
   ],
   "source": [
    "#считаем accuracy сетов с разной фильтрацией, на основной выборке. [0] = neg, [1] = pos, [0] = ns\n",
    "for i in range(3):\n",
    "    res1 = accuracy_var(rating1_text, negat[i], posit[i])\n",
    "    res5 = accuracy_var(rating5_text, negat[i], posit[i])\n",
    "    print('Filtre at frequency ', i+1)\n",
    "    print('True positive=', res5[1], 'True negative=', res1[0], 'False positive', res1[1], 'False negative', res5[0], 'Not stated', res1[2]+res5[2])\n",
    "    acc = (res1[0] + res5[1])/(res1[0]+res1[1]+res5[0]+res5[1])\n",
    "    print('Accuracy=', acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtre at frequency  1\n",
      "True positive= 10 True negative= 9 False positive 0 False negative 0 Not stated 1\n",
      "Accuracy= 1.0\n",
      "Filtre at frequency  2\n",
      "True positive= 7 True negative= 7 False positive 0 False negative 0 Not stated 6\n",
      "Accuracy= 1.0\n",
      "Filtre at frequency  3\n",
      "True positive= 7 True negative= 8 False positive 0 False negative 2 Not stated 3\n",
      "Accuracy= 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "#считаем accuracy сетов с разной фильтрацией, на тестовых данных\n",
    "for i in range(3):\n",
    "    res1 = accuracy_var(rating1_test, negat[i], posit[i])\n",
    "    res5 = accuracy_var(rating5_test, negat[i], posit[i])\n",
    "    print('Filtre at frequency ', i+1)\n",
    "    print('True positive=', res5[1], 'True negative=', res1[0], 'False positive', res1[1], 'False negative', res5[0], 'Not stated', res1[2]+res5[2])\n",
    "    acc = (res1[0] + res5[1])/(res1[0]+res1[1]+res5[0]+res5[1])\n",
    "    print('Accuracy=', acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выброс слов с низкой частотностью снижает качество работы, особенно сильно растёт False negative. Это вполне ожидаемо, учитывая особенности отзывов: положительные отзывы намного короче отрицательных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как улучшить предложенный алгоритм?  \n",
    "1. При оценке тональности сейчас достаточно, чтобы объём пересечений с одним из оценочных множеств был больше:\n",
    "    elif len(review_lemmas & negat) == 0 or len(review_lemmas & posit)/len(review_lemmas & negat) > 1:\n",
    "        res = 'positive'\n",
    "    elif len(review_lemmas & posit) == 0 or len(review_lemmas & negat)/len(review_lemmas & posit) > 1:\n",
    "        res = 'negative'\n",
    "Но у нас явный перекос в сторону отрицательных элементов, 338:158, и при равных весах часто возникает False negative. Поэтому можно было бы дать положительным леммам больший вес, признавать отзыв негативным при перевесе, например, в 338/158, т.е. примерно 2.14 раза, и наоборот для положительных: 158/338, примерно 0,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tone_normalized(review, negat, posit):\n",
    "    res = ''\n",
    "    # лемматизируем отзыв\n",
    "    review_tokens = [w.lower() for w in wordpunct_tokenize(review) if w.isalpha()]\n",
    "    review_lemmas = set((nlp(token)[0].lemma_ for token in review_tokens))\n",
    "    if len(review_lemmas & negat) == 0 and len(review_lemmas & posit) == 0: # если в отзыве нет лемм из оценочных множеств, то и определить тональность нельзя\n",
    "        res = 'not stated'\n",
    "    elif len(review_lemmas & negat) == 0 or len(review_lemmas & posit)/len(review_lemmas & negat) > 0.5:\n",
    "        res = 'positive'\n",
    "    elif len(review_lemmas & posit) == 0 or len(review_lemmas & negat)/len(review_lemmas & posit) > 2.14:\n",
    "        res = 'negative'\n",
    "    else:\n",
    "        res = 'not stated' # сюда попадают отзывы с равным объёмом пересечений с каждым оценочным множеством\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_var_normalized(text, negat, posit):\n",
    "    neg = 0\n",
    "    pos = 0\n",
    "    ns = 0\n",
    "    for review in text:\n",
    "        res = tone_normalized(review, negat, posit)\n",
    "        if res == 'negative':\n",
    "            neg += 1\n",
    "        elif res == 'positive':\n",
    "            pos += 1\n",
    "        elif res == 'not stated':\n",
    "            ns += 1\n",
    "    return(neg, pos, ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive= 56 True negative= 67 False positive 2 False negative 11 Not stated 48\n",
      "Accuracy= 0.9044117647058824\n"
     ]
    }
   ],
   "source": [
    "res1 = accuracy_var_normalized(rating1_text, negat[2], posit[2])\n",
    "res5 = accuracy_var_normalized(rating5_text, negat[2], posit[2])\n",
    "print('True positive=', res5[1], 'True negative=', res1[0], 'False positive', res1[1], 'False negative', res5[0], 'Not stated', res1[2]+res5[2])\n",
    "acc = (res1[0] + res5[1])/(res1[0]+res1[1]+res5[0]+res5[1])\n",
    "print('Accuracy=', acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат при равных весах:\n",
    "Filtre at frequency  3\n",
    "True positive= 49 True negative= 69 False positive 1 False negative 15 Not stated 50\n",
    "Accuracy= 0.8805970149253731"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Для коррекции перекоса в сторону отрицательных отзывов можно также добавить в множество положительной оценки частотные слова положительных отзывов (за исключением стоп-слов), которые встречаются и в отрицательных отзывах. У меня слишком мало времени до дедлайна, чтобы сделать всё красиво, поэтому я добавлю несколько самых частотных слов вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = defaultdict(int)\n",
    "for lemma in rating5_lemmas:\n",
    "    d[lemma] += 1\n",
    "for key in sorted(d, key=d.get, reverse=True):\n",
    "    print(key, d[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "work good like use ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in ['work', 'good', 'like', 'use', 'ok']:\n",
    "    posit[2].add(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive= 68 True negative= 64 False positive 4 False negative 12 Not stated 36\n",
      "Accuracy= 0.8918918918918919\n"
     ]
    }
   ],
   "source": [
    "res1 = accuracy_var(rating1_text, negat[2], posit[2])\n",
    "res5 = accuracy_var(rating5_text, negat[2], posit[2])\n",
    "print('True positive=', res5[1], 'True negative=', res1[0], 'False positive', res1[1], 'False negative', res5[0], 'Not stated', res1[2]+res5[2])\n",
    "acc = (res1[0] + res5[1])/(res1[0]+res1[1]+res5[0]+res5[1])\n",
    "print('Accuracy=', acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат с исходным множеством позитивных токенов:\n",
    "Filtre at frequency  3\n",
    "True positive= 49 True negative= 69 False positive 1 False negative 15 Not stated 50\n",
    "Accuracy= 0.8805970149253731"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
